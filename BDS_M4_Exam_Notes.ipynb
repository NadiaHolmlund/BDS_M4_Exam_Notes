{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT/TbC8D2P68fR5dRWrcMO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaHolmlund/BDS_M4_Exam_Notes/blob/main/BDS_M4_Exam_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# History"
      ],
      "metadata": {
        "id": "tyfbxp6jqTYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Terms"
      ],
      "metadata": {
        "id": "G6iUORcOoeFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biological Analogies"
      ],
      "metadata": {
        "id": "RGiQOby7qtyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feedforward Neural Networks"
      ],
      "metadata": {
        "id": "wv_eNB60qnOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors"
      ],
      "metadata": {
        "id": "eOWaS5U3pJHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ],
      "metadata": {
        "id": "scL7FL8Tr4cD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation Functions"
      ],
      "metadata": {
        "id": "8ZZFj9T7rBBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weights"
      ],
      "metadata": {
        "id": "5rqVSfSRq_vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Functions"
      ],
      "metadata": {
        "id": "SqnGUhv3sB-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Score"
      ],
      "metadata": {
        "id": "j3-uJcvHswLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output"
      ],
      "metadata": {
        "id": "1QfB8HL2r-y6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate"
      ],
      "metadata": {
        "id": "BSSbquLUybWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The learning rate is a hyperparameter that controls the step size at which a neural network learns from the training data during the optimization process.\n",
        "\n",
        "In a neural network, the optimization process involves adjusting the weights and biases of the network to minimize the difference between the predicted output and the true output. The learning rate determines the size of the steps taken towards the optimal weights and biases during this process.\n",
        "\n",
        "- High learning rate: weights and biases are adjusted more aggressively, resulting in faster convergence to the optimal values. However, it may overshoot the optimal values and fail to converge.\n",
        "\n",
        "- Low learning rate: weights and biases are adjusted more slowly, which may require more iterations to reach the optimal values. However, it's less likely to overshoot the optimal values and may result in a more accurate final model.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screen-Shot-2018-02-24-at-11.47.09-AM.png)"
      ],
      "metadata": {
        "id": "P9_dY32e_zeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size"
      ],
      "metadata": {
        "id": "zasunp_UydJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size is a hyperparameter that determines the number of samples processed by a neural network in each training iteration.\n",
        "\n",
        "When training a neural network, the entire training dataset is typically too large to be processed at once. Instead, the training dataset is divided into smaller batches of samples that can be processed in parallel. The batch size determines the number of samples in each batch.\n",
        "\n",
        "A larger batch size means that more samples are processed in each iteration, which can result in faster training times on modern parallel processors. However, larger batch sizes also require more memory and may lead to overfitting if the model starts to memorize the training set.\n",
        "\n",
        "Conversely, a smaller batch size means that fewer samples are processed in each iteration, which can result in slower training times but may also lead to better generalization performance by preventing overfitting.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/223642c7.jpg)"
      ],
      "metadata": {
        "id": "qWCLSeshA5QE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epochs"
      ],
      "metadata": {
        "id": "FJ7mrFdjyefk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of epochs is a hyperparameter that determines how many times the neural network will train on the entire dataset. Typically, the number of epochs is selected to balance between training the model long enough to converge to an optimal solution and preventing overfitting.\n",
        "\n",
        "An epoch refers to a complete iteration over the entire training dataset. During an epoch, the neural network is trained on every sample in the training dataset at least once.\n",
        "\n",
        "In machine learning, the goal is to minimize the difference between the predicted output and the true output. This is achieved by iteratively adjusting the weights and biases of the neural network using optimization algorithms. During each epoch, the optimization algorithm processes all the training samples in the dataset and updates the weights and biases of the network accordingly.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/fa798161.jpg)"
      ],
      "metadata": {
        "id": "V5nxOBdoBp8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wandb.ai"
      ],
      "metadata": {
        "id": "s4KQzrEvzhvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wandb.ai is a performance visualization tool that can be used to track and visualize the performance of machine learning models in real-time. It allows you to easily visualize and analyze the results of your experiments, compare different models, and share your results with others.\n",
        "\n",
        "Wandb.ai can be used to track and visualize a variety of metrics such as accuracy, loss, and learning rate during the training process. It can also track other useful information such as model hyperparameters, dataset statistics, and hardware usage.\n",
        "\n"
      ],
      "metadata": {
        "id": "cT4oihpxzkHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architectures"
      ],
      "metadata": {
        "id": "ve8qvVDzpJFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "29HL2U2-sftC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation Algorithm"
      ],
      "metadata": {
        "id": "ttdcde35smxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State"
      ],
      "metadata": {
        "id": "hjpIrqsEDmma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "hjQUvmXRpJDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Milestone Transformer Architectures"
      ],
      "metadata": {
        "id": "mwztcptWpI_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classical Neural Network Architectures"
      ],
      "metadata": {
        "id": "sfRFfh3HqaZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "8yAkD8V3rJ_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network (ANN)"
      ],
      "metadata": {
        "id": "SXjZkI57oft7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NO MEMORY - Cannot be used on sequential data but can be used for cross-sectional prediction problems (e.g. identify cats and dogs**"
      ],
      "metadata": {
        "id": "kPquard5DKlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "DDS3tjlqolJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NO MEMORY - Cannot be used on sequential data but can be used for cross-sectional prediction problems (e.g. identify cats and dogs**\n",
        "\n",
        "A Convolutional Neural Network (CNN) is a type of deep learning algorithm designed to analyze and recognize visual patterns. It is inspired by the way our brain processes visual information.\n",
        "\n",
        "CNNs are made up of multiple layers of neurons that perform operations called convolutions. During convolution, the network processes the input image by applying a series of filters, which extract certain features from the image. These filters can detect patterns such as edges, corners, and curves.\n",
        "\n",
        "The output of one layer is fed as input to the next layer, and each layer learns to detect more complex features. The final layer of the network performs a classification task by identifying which object or feature is present in the input image.\n",
        "\n",
        "CNNs are commonly used in image and video recognition, object detection, and natural language processing tasks."
      ],
      "metadata": {
        "id": "T12hWpkhz--_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computer Vision"
      ],
      "metadata": {
        "id": "P8vDWc_Kt6LR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a CNN, the input image is represented as a 3D matrix where the first two dimensions represent the height and width of the image, and the third dimension represents the color channels. Here's an example of what a 3D matrix of an input image might look like:"
      ],
      "metadata": {
        "id": "q0z71yUp0zef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[\n",
        "  [[100, 120,  80], [ 90, 100,  70], [110, 105,  75]],\n",
        "  [[ 80,  90,  60], [ 75,  80,  55], [ 85,  75,  50]],\n",
        "  [[120, 125,  85], [110, 120,  80], [130, 115,  90]]\n",
        "]"
      ],
      "metadata": {
        "id": "gFMIY4ia092V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a 3x3x3 matrix, meaning it has 3 rows, 3 columns, and 3 color channels (red, green, and blue). Each element in the matrix represents the intensity value of a pixel at a specific location in the image.\n",
        "\n",
        "For example, in the first list [100, 120, 80], the first number 100 represents the intensity value of the red channel, the second number 120 represents the intensity value of the green channel, and the third number 80 represents the intensity value of the blue channel for the pixel located at the top-left corner of the input image."
      ],
      "metadata": {
        "id": "QGUkK5xC1AHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/maxresdefault.jpg)\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.20.29.png)"
      ],
      "metadata": {
        "id": "_5ec66iNwEw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Architecture"
      ],
      "metadata": {
        "id": "W1AXvSISuBX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.28.39.png)\n",
        "\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.29.39.png)"
      ],
      "metadata": {
        "id": "iR1SbGL4xTWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolution Layer & Convolution Filter"
      ],
      "metadata": {
        "id": "JL2XDvF6uFQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolution Layer**\n",
        "A convolution layer extracts features from an input image by applying a set of filters or kernels.\n",
        "\n",
        "During the convolution operation, each filter slides over the input image pixel by pixel, computing the dot product between the filter weights and the corresponding pixel values of the input image. This produces a single value in the output feature map. The filter then slides to the next pixel and the process is repeated until the filter has scanned the entire input image.\n",
        "\n",
        "By using multiple filters in a convolution layer, the CNN can detect a wide variety of features at different locations within the input image, such as edges, corners, and curves. These features can then be combined by subsequent layers of the network to recognize more complex patterns and objects within the image.\n",
        "\n",
        "Convolution layers are usually followed by other types of layers such as pooling layers or activation layers to further process the extracted features before passing them on to the next layer in the network.\n",
        "\n",
        "**Convolution Filter**\n",
        "A convolution filter, also known as a kernel, is a small matrix of numbers. The filter slides across the image, performing a mathematical operation at each position to create a new output feature map.\n",
        "\n",
        "Filters can be designed to detect different types of features and multiple filters are usually applied to the input image in a single convolution layer to extract different types of features. The resulting feature maps are then passed on to subsequent layers of the network for further processing and classification.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.32.57.png)\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.17.png)\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.06.png)"
      ],
      "metadata": {
        "id": "4i_lUgRiy0Bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downsampling (Pooling)"
      ],
      "metadata": {
        "id": "frnaEsJUuOVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downsampling is a technique to reduce the spatial dimensions of an image while retaining the important features and reduce computational complexity and prevent overfitting. This is also called pooling.\n",
        "\n",
        "During the pooling operation, a small window, usually 2x2 or 3x3, is slid over the feature map and a single value is selected from the window based on a specific rule, such as taking the maximum or average value, or global in the window. This reduces the size of the feature map by a factor of the window size.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.27.png)"
      ],
      "metadata": {
        "id": "Ydd9oP3LzHx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flattening"
      ],
      "metadata": {
        "id": "2OfK0L0Mw2T4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening refers to the process of converting a multi-dimensional tensor, such as a feature map, into a one-dimensional vector that can be fed into a fully connected layer for classification.\n",
        "\n",
        "After a series of convolution and pooling layers, the output feature map is a multi-dimensional tensor with height, width, and depth dimensions. Flattening this tensor involves rearranging the elements of the tensor into a single vector, which can then be fed into a fully connected layer for classification.\n",
        "\n",
        "For example, if the output feature map has dimensions of 7x7x64, flattening would result in a vector of length 3136 (7 x 7 x 64 = 3136)."
      ],
      "metadata": {
        "id": "0qB2C9gQ7780"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fully Connected Layers"
      ],
      "metadata": {
        "id": "domidFRLuSGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fully connected layer takes the output from the preceding convolution and pooling layers and performs a matrix multiplication with weights and biases to produce a classification output.\n",
        "\n",
        "A fully connected layer treats the input feature map as a one-dimensional vector and connects every neuron in the layer to every neuron in the previous layer. This means that every feature learned by the preceding layers can be used to make a prediction.\n",
        "\n",
        "The weights and biases in the fully connected layer are learned during the training process using backpropagation, which adjusts the values of the weights and biases to minimize the error between the predicted output and the true label."
      ],
      "metadata": {
        "id": "a5k_HNNL9xCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Region-Based Convolutional Neural Network (R-CNN)"
      ],
      "metadata": {
        "id": "qhOt9pf7uVnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used for object detection in images.\n",
        "\n",
        "R-CNN uses a combination of convolutional neural networks and region proposal algorithms to identify objects in an image.\n",
        "\n",
        "The R-CNN algorithm consists of three main components:\n",
        "\n",
        "Region proposal: a selective search algorithm that generates a set of candidate regions in an image that may contain objects.\n",
        "Feature extraction: a CNN is applied to each candidate region to extract a fixed-length feature vector.\n",
        "Classification: a set of support vector machines (SVMs) is trained to classify the feature vectors into the different object categories.\n",
        "The R-CNN approach enables the CNN to be applied to smaller, more localized regions of an image, reducing the computational burden of processing the entire image. \n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.40.png)\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.51.png)"
      ],
      "metadata": {
        "id": "91voleIqzONo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Optimization"
      ],
      "metadata": {
        "id": "Jm0XcQ_3uZ9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hyper-parameter tuning: learning rate, batch size, epochs, number of filters in each convolutional layer\n",
        "- Data augmentation: increase dataset size by rotating, flipping, scaling\n",
        "- Transfer learning: using a pre-trained models and fine-tune with your dataset\n",
        "- Regularization: dropout, L1/L2 regularization, and early stopping\n",
        "- Change architecture: find the optimal network architecture for a given problem (use academic articles)"
      ],
      "metadata": {
        "id": "N8yX_RVQyR97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Business Applications"
      ],
      "metadata": {
        "id": "87sx1D64ueHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Image analysis\n",
        "- Video analysis\n",
        "- E.g. autonomous driving\n",
        "- E.g. facial recognition*"
      ],
      "metadata": {
        "id": "GyFcGLtBuoKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Network (RNN)"
      ],
      "metadata": {
        "id": "wwhjxlWGorYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HAS MEMORY - Can be used on sequential data**\n",
        "\n",
        "Sequential prediction problems:\n",
        "- To process a sequence or a temporal series of data points, you have to show the entire sequence to the network at once: turn it into a single data point.\n",
        "Therefore, often we would like to operate over sequences of vectors: Sequences in the input, the output, or in the most general case both.\n",
        "- Biological intelligence processes information incrementally while maintaining an internal model of what it’s processing, built from past information and constantly updated as new information comes in. Our thoughts have persistence.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_lstm_1.jpeg)"
      ],
      "metadata": {
        "id": "h-9XT1suDaC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Architecture"
      ],
      "metadata": {
        "id": "vuaXEv9bEt28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RNNs are networks with internal loops, allowing information to persist.\n",
        "- It processes sequences by iterating through the elements and maintaining a state containing information relative to what it has seen so far.\n",
        "- The state of the RNN is reset between processing two different, independent sequences, so you still consider one sequence a single data point: a single input to the network.\n",
        "- What changes is that this data point is no longer processed in a single step; rather, the network internally loops over sequence elements.\n",
        "\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_rnn_0.png)\n",
        "\n",
        "- Recurrent neural networks have the form of a chain of repeating modules of neural network.\n",
        "- In standard RNNs, this repeating module will have a very simple structure, such as a single tanh() layer.\n",
        "- It takes (differently) weighted input from the cells in the layer below, as well as of the state, which is just the “saved”/“remembered” layer below how it was one time-step earlier (at t-1).\n",
        "- Then, with the tanh(), it squisches all the weights together to an output bounded between [-1,1].\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_LSTM1.png)"
      ],
      "metadata": {
        "id": "QWTwEYMOGY9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loops"
      ],
      "metadata": {
        "id": "TcooySQGE7GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_t = 0 # the state as t\n",
        "\n",
        "for (input_t in input_sequence) {\n",
        "  output_t = f(input_t, state_t)\n",
        "  state_t = output_t                   \n",
        "}"
      ],
      "metadata": {
        "id": "PKP1ENkDHgCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To make these notions of loop and state clear, let’s implement the forward pass of a toy RNN .\n",
        "- This RNN takes as input a sequence of vectors, which you’ll encode as a 2D tensor of size (timesteps, input_features).\n",
        "- It loops over timesteps, and at each timestep, it considers its current state at t and the input at t (of shape (input_features), and combines them to obtain the output at t.\n",
        "- You’ll then set the state for the next step to be this previous output.\n",
        "For the first timestep, the previous output isn’t defined; hence, there is no current state. So, you’ll initialize the state as an all-zero vector called the initial state of the network."
      ],
      "metadata": {
        "id": "_OjnKh-iHlIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_t <- 0\n",
        "\n",
        "for (input_t in input_sequence) {\n",
        "  output_t <- activation(dot(W, input_t) + dot(U, state_t) + b)\n",
        "  state_t <- output_t\n",
        "}"
      ],
      "metadata": {
        "id": "ko7-8TwZHspT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can even flesh out the function f: the transformation of the input and state into an output will be parameterized by two matrices, W and U, and a bias vector b.\n",
        "- It’s similar to the transformation operated by a densely connected layer in a feedforward network."
      ],
      "metadata": {
        "id": "Q1Xl18cpHt6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations of RNN"
      ],
      "metadata": {
        "id": "LoMDOF-TFC3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Long-term Dependencies"
      ],
      "metadata": {
        "id": "e2DIM33rFHHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task.\n",
        "\n",
        "- Yet, going one step back is often not good enough, since meaning in some cases unfolds over a long sequence.\n",
        "\n",
        "- We just stack several layer_simple_rnnon top of each other to capture the information contained in long sequences? Kind of, but there is a probhlem…\n",
        "\n",
        "- In theory, RNNs are absolutely capable of handling such long-term dependencies.\n",
        "\n",
        "- Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by Hochreiter (1991, in German) and Bengio, et al. (1994)[^1], who found some pretty fundamental reasons why it might be difficult.\n",
        "\n",
        "- First and foremost, the valishing gradient problem."
      ],
      "metadata": {
        "id": "IUYCAt8iH3GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Backpropagation Through Time (BPTT)"
      ],
      "metadata": {
        "id": "ohF7OrTqFK1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Remember, the purpose of RNNs is to accurately classify sequential input.\n",
        "- We rely on the backpropagation of error and gradient descent to do so.\n",
        "- RNNs rely on an extension of backpropagation called backpropagation through time, or BPTT.\n",
        "- Time, in this case, is simply expressed by a well-defined, ordered series of calculations linking one time step to the next, which is all backpropagation needs to work.\n",
        "- Remember, neural networks, whether they are recurrent or not, are simply nested composite functions like y = f(g(h(x))).\n",
        "- Adding a time element only extends the series of functions for which we calculate derivatives with the chain rule."
      ],
      "metadata": {
        "id": "jX3ZXcbHH8gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Vanishing (Exploding) Gradient"
      ],
      "metadata": {
        "id": "5GGq8EwQCvZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Information flowing through neural nets passes through many stages of multiplication.\n",
        "- Because the layers and time steps of deep neural networks relate to each other through multiplication, derivatives are susceptible to vanishing or exploding.\n",
        "- This is an effect that is similar to what is observed with non-recurrent networks (feedforward networks) that are many layers deep: as you keep adding layers to a network, the network eventually becomes untrainable.\n",
        "- Exploding gradients treat every weight as though it were the proverbial butterfly whose flapping wings cause a distant hurricane.\n",
        "- Those weights’ gradients become saturated on the high end; i.e. they are presumed to be too powerful.\n",
        "- But exploding gradients can be solved relatively easily, because they can be truncated or squashed. Vanishing gradients can become too small for computers to work with or for networks to learn – a harder problem to solve.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_vanishing_gradient.png)\n",
        "\n",
        "- Here you see the effects of applying a sigmoid function over and over again.\n",
        "- The data is flattened until, for large stretches, it has no detectable slope.\n",
        "- This is analogous to a gradient vanishing as it passes through many layers."
      ],
      "metadata": {
        "id": "ulUCNUt3ICG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary"
      ],
      "metadata": {
        "id": "UBrrdMUqIpgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In order to exploit the information of multiple recurrent layers, we have to find a way to train the weights while avoiding the vanishing gradient problem.\n",
        "- Therefore we introduce gates, through which previous states can pass through quasi unaltered."
      ],
      "metadata": {
        "id": "ctGClMsdIqlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Long Short-Term Neural Network (LSTM)"
      ],
      "metadata": {
        "id": "jO_4qjBUorWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HAS MEMORY - Can be used on sequential data**\n",
        "\n",
        "Sequential prediction problems:\n",
        "- To process a sequence or a temporal series of data points, you have to show the entire sequence to the network at once: turn it into a single data point.\n",
        "Therefore, often we would like to operate over sequences of vectors: Sequences in the input, the output, or in the most general case both.\n",
        "- Biological intelligence processes information incrementally while maintaining an internal model of what it’s processing, built from past information and constantly updated as new information comes in. Our thoughts have persistence.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_lstm_1.jpeg)"
      ],
      "metadata": {
        "id": "j4xyEHqfGRrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Architecture"
      ],
      "metadata": {
        "id": "apW82QZwFRLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1: The Forget Gate Layer"
      ],
      "metadata": {
        "id": "5KA6TjWOFVCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2: The Input Gate Layer"
      ],
      "metadata": {
        "id": "JPEVgBMBFXGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3: The Output Gate Layer"
      ],
      "metadata": {
        "id": "tUFhUKbFFZ1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary"
      ],
      "metadata": {
        "id": "qnGqaHEvImQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- In order to exploit the information of multiple recurrent layers, we have to find a way to train the weights while avoiding the vanishing gradient problem.\n",
        "- Therefore we introduce gates, through which previous states can pass through quasi unaltered.\n",
        "- However, not every information from previous sequences is useful for us. Indeed, too much information could be a curse rather than a blessing for our model.\n",
        "- Therefore, we have to introduce further gates that decide which information from previous stages to remember, and which to forget."
      ],
      "metadata": {
        "id": "7Elni06bIgqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Models"
      ],
      "metadata": {
        "id": "OJ5U3pxsorUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SBERT"
      ],
      "metadata": {
        "id": "vr4wV4J7pcXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "o20rYM3mpcSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simpletransformers\n"
      ],
      "metadata": {
        "id": "fqbXoYYEpcJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "4OKEkH-FtB3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "RyJJE20KzbHe"
      }
    }
  ]
}