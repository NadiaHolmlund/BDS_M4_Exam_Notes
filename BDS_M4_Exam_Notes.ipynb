{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy1NS+WSbuYpQEEeCtqVef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaHolmlund/BDS_M4_Exam_Notes/blob/main/BDS_M4_Exam_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-exhaustive list of example questions"
      ],
      "metadata": {
        "id": "ARp1UJKF-WUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explain briefly the main architecture of an ANN, including all important components and mechanisms."
      ],
      "metadata": {
        "id": "SrkBkKMB9wnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Artificial Neural Network (ANN) is a computational model inspired by the structure and functioning of the human brain. It consists of input, hidden, and output layers. The input layer receives the input data, the hidden layer processes the data using weights and biases, and the output layer produces the predicted output. During training, the weights and biases are adjusted using an optimization algorithm such as stochastic gradient descent to minimize the error between the predicted and actual outputs."
      ],
      "metadata": {
        "id": "w6aDSlAiDf96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is stochastic gradient descent (SGD)?"
      ],
      "metadata": {
        "id": "2D2dVeZn9y1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic gradient descent (SGD) is an optimization algorithm used to train machine learning models. It updates the model's parameters iteratively by calculating the gradient of the loss function with respect to the parameters on a small subset of the training data at each iteration. It uses a learning rate to control the step size of each update."
      ],
      "metadata": {
        "id": "BW1CGpYfDoOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explain the backpropagation algorithm for training neural networks."
      ],
      "metadata": {
        "id": "piHSkLqU91Bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagation is a supervised learning algorithm used to train artificial neural networks. It involves computing the gradients of the loss function with respect to the network's parameters using the chain rule of calculus and propagating them backward through the network. This allows the network to adjust the weights and biases to improve its predictions."
      ],
      "metadata": {
        "id": "Wb1ACYzCDw44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the difference between SGD and backpropagation"
      ],
      "metadata": {
        "id": "MZ04F3iJF6NG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic gradient descent (SGD) and backpropagation are two separate but related concepts in machine learning.\n",
        "\n",
        "Stochastic gradient descent is an optimization algorithm used to minimize the loss function of a neural network during training. It works by updating the weights of the network based on the gradient of the loss function with respect to the weights. In each iteration, SGD randomly selects a batch of samples from the training data to compute the gradient and update the weights.\n",
        "\n",
        "Backpropagation, on the other hand, is an algorithm used to calculate the gradient of the loss function with respect to the weights of a neural network. It works by propagating the error from the output layer back through the layers of the network to compute the gradient of the loss function with respect to each weight.\n",
        "\n",
        "In other words, backpropagation is used to compute the gradient needed for stochastic gradient descent to update the weights. They are often used together during the training of neural networks, where backpropagation is used to calculate the gradient and SGD is used to update the weights."
      ],
      "metadata": {
        "id": "jwrFx-ZfF5fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is regularization, and how does it help prevent overfitting in neural networks?"
      ],
      "metadata": {
        "id": "2KRp-lRM94RR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization is a technique used to prevent overfitting in machine learning models. It involves adding a penalty term to the loss function to encourage the model to learn simpler patterns. This can be done through techniques such as L1 and L2 regularization, which encourage sparsity in the weights, or dropout regularization, which randomly drops out some neurons during training to prevent overreliance on specific features.\n",
        "\n",
        "L1 regularization, also known as Lasso regularization, adds a penalty term to the loss function proportional to the absolute value of the weights. The L1 regularization encourages the model to have sparse weight values, which means that some weights may become exactly zero. This can be useful for feature selection, where some of the input features may be irrelevant or redundant. The regularization parameter λ determines the strength of the penalty term.\n",
        "\n",
        "L2 regularization, also known as Ridge regularization, adds a penalty term to the loss function proportional to the squared value of the weights. The L2 regularization encourages the model to have small but non-zero weight values. This can help to prevent the weights from becoming too large, which can lead to overfitting. The regularization parameter λ determines the strength of the penalty term."
      ],
      "metadata": {
        "id": "igcGDFXgD4Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are the benefits and drawbacks of using dropout regularization in neural networks?"
      ],
      "metadata": {
        "id": "2jpOCjwA97I0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout regularization randomly drops out (i.e. set weight to zero) some neurons during training to prevent overfitting. This forces the network to learn a more robust representation of the input by preventing it from relying too heavily on any one feature.\n",
        "\n",
        "Benefits:\n",
        "- reducing overfitting\n",
        "- improving generalization\n",
        "\n",
        "Drawbacks:\n",
        "- increasing the training time\n",
        "- potentially decreasing the model's accuracy"
      ],
      "metadata": {
        "id": "h5kzjAgDD-xs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is early dropout?"
      ],
      "metadata": {
        "id": "dXJYfjjCBPaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training, the performance of the model on the validation set is monitored at regular intervals. If the performance on the validation set starts to deteriorate while the performance on the training set continues to improve, then the model is likely overfitting the training data. At this point, training can be stopped early, and the model with the best performance on the validation set is chosen as the final model."
      ],
      "metadata": {
        "id": "27O2dNkoBSN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are convolutional neural networks (CNNs), and how are they used in image recognition and other tasks?"
      ],
      "metadata": {
        "id": "s7Qt5nqQ99C0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Networks (CNNs) are a type of neural network commonly used for image recognition and other tasks involving spatial data. They use convolutional layers to extract features from the input data, followed by pooling layers to reduce the dimensionality of the output. This makes them well-suited for tasks that require the identification of spatial patterns, such as identifying objects in images."
      ],
      "metadata": {
        "id": "drOcRPO7EF0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is pooling, and how does it help reduce the dimensionality of CNN outputs?"
      ],
      "metadata": {
        "id": "Yw3CR6i49_xR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling is a technique used in CNNs to reduce the dimensionality of the output. It involves dividing the output into small regions and summarizing each region with a single value. This helps to reduce the computational complexity of the network and prevent overfitting."
      ],
      "metadata": {
        "id": "RfHigjBsEMRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is transfer learning, and how can it be used to improve the performance of deep learning models?"
      ],
      "metadata": {
        "id": "cAUFB4Ll-BXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning is a technique used to improve the performance of deep learning models by leveraging knowledge learned from previous tasks. It involves reusing a pre-trained model and fine-tuning it on a new task. This can save training time and improve the accuracy of the model."
      ],
      "metadata": {
        "id": "SEo3JYnhEQjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are recurrent neural networks (RNNs), and how are they used in sequence prediction tasks?"
      ],
      "metadata": {
        "id": "4c0Ofdq6-DzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recurrent Neural Networks (RNNs) are a type of neural network commonly used for sequence prediction tasks. They use recurrent connections to allow information to persist through time, making them well-suited for tasks such as language modeling and speech recognition."
      ],
      "metadata": {
        "id": "5MtwTYovEVI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the vanishing gradient problem in RNNs, and how can it be addressed?"
      ],
      "metadata": {
        "id": "HVm2z-K0-Fv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The vanishing gradient problem in RNNs occurs when the gradients of the loss function with respect to the network's parameters become very small as they are propagated backward through time. This can make it difficult to train the network effectively. It can be addressed using techniques such as gradient clipping, which limits the size of the gradients, or gating mechanisms such as Long Short-Term Memory (LSTM) cells, which allow the network to selectively remember or forget information."
      ],
      "metadata": {
        "id": "RZGv1mo4Ebpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is attention, and how is it used in transformer models?"
      ],
      "metadata": {
        "id": "GzXOGHse-HxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention is a mechanism used in transformer models to allow the network to selectively focus on different parts of the input data. It involves computing attention scores between each pair of input tokens and using these scores to weight the contributions of each token to the output."
      ],
      "metadata": {
        "id": "e3lKFFGREh4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the self-attention mechanism, and how does it help transformers model dependencies between different input tokens?"
      ],
      "metadata": {
        "id": "XJpXydsY-J2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-attention is a variant of attention used in transformer models. It allows the model to calculate attention weights between different positions of a single input sequence. This helps the model to understand the dependencies between different parts of the input sequence and to identify important features that are relevant to the task."
      ],
      "metadata": {
        "id": "_7RYZZ81E2Eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the pre-training/fine-tuning approach for training large language models, such as BERT or GPT?"
      ],
      "metadata": {
        "id": "SeOzGxF5-Ltp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-training/fine-tuning is an approach to training large language models such as BERT or GPT. The model is first pre-trained on a large amount of data, typically using an unsupervised learning method. This pre-training allows the model to learn general language patterns and structures. The model is then fine-tuned on a smaller dataset for a specific downstream task, such as sentiment analysis or question-answering. Fine-tuning allows the model to adapt its learned knowledge to the specific task at hand."
      ],
      "metadata": {
        "id": "Fq1opFrPE81h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How does BERT use masked language modeling to pre-train a bidirectional language model?"
      ],
      "metadata": {
        "id": "fdZ6jbYW-NnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT uses a masked language modeling technique to pre-train a bidirectional language model. In this technique, some of the words in the input sequence are randomly masked and the model is trained to predict the masked words based on the context of the other words in the sequence. This allows the model to learn about the relationships between different words in the sequence in both forward and backward directions, making it bidirectional."
      ],
      "metadata": {
        "id": "AgKquYSPFEqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What differentiates SBERT from BERT models. When would you typically prefer using one over the other?"
      ],
      "metadata": {
        "id": "UMPdtLqD-QK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SBERT stands for Sentence-BERT, which is a variant of BERT designed specifically for sentence-level tasks such as sentence classification or semantic similarity. SBERT modifies the BERT model architecture by adding pooling layers to create sentence embeddings. These embeddings can be used to compare the similarity between sentences or to classify them into different categories. You would typically prefer SBERT for tasks that require sentence-level understanding, while BERT would be preferred for more general language modeling tasks."
      ],
      "metadata": {
        "id": "sj60mFTOFMbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the difference between generative and discriminative models, and give an example of each."
      ],
      "metadata": {
        "id": "Sj5i8tqR-Sc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative models\n",
        "- generate new data similar to the training data\n",
        "- E.g. image synthesis, speech generation, and language modeling.\n",
        " - Variational Autoencoder (VAE) - learns to encode and generate data, typically images\n",
        " - Generative Adversarial Networks (GANs) - learns to generate realistic images by training a generator network to fool a discriminator network.\n",
        "\n",
        "Discriminative models\n",
        "- models the decision boundary between classes of data and classify new samples based on this boundary\n",
        "- E.g. image classification, sentiment analysis, and speech recognition.\n",
        " - Support Vector Machines (SVMs) - learns to classify data by finding the hyperplane that maximally separates the different classes.\n",
        " - Logistic Regression - learns to predict the probability of a binary or multiclass outcome based on the input data.\n",
        " - Convolutional Neural Networks (CNNs) - learns to classify images by identifying patterns and features in the input data."
      ],
      "metadata": {
        "id": "rfYRyR-aFU2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# History"
      ],
      "metadata": {
        "id": "tyfbxp6jqTYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Cybernetics: (1940s-1960s) developments in theories of biological learning and the training of simple models with a single neuron\n",
        "- Connectionism (1980s-1990s) methodological advances that  allowed faster training of ANN's with a few hidden layers\n",
        "- 2006 - onwards: appellative deep learning\n",
        "- 2015-2017: Modern Dl frameworks Tensorflow and PyTorch appear.\n",
        "- Now (2023) Generative models, diffusion models, and transformer have reached industry grade \n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_timeline-2.jpg)"
      ],
      "metadata": {
        "id": "mDbRDIzgJWES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Terms"
      ],
      "metadata": {
        "id": "G6iUORcOoeFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "_rZhkPzRJM69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/dl_overview.png)"
      ],
      "metadata": {
        "id": "A6l6CnaHI3EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biological Analogies"
      ],
      "metadata": {
        "id": "RGiQOby7qtyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analogies with human brain:\n",
        "\n",
        "- The units of calculation in an ANN are called neurons.\n",
        "- The neurons are connected via synapses which are weighted.\n",
        "- The network learns to accomplish a given task by adjusting these weights inputs.\n",
        "\n",
        "\n",
        "NN model decision processes in the following steps:\n",
        "- Take input cells (neurons or units), and connect them to some output cell (in neuroscience, via a synapse)\n",
        "- The receiving cell’s input is equal to the submitting cell’s output, weighted by the strength of the connection\n",
        "- The cell transforms this input via a non-linear activation function to an output, which it in turn submits to other connected cells\n",
        "\n",
        "We refer to networks because the final architecture is obtained by composing together many different functions\n",
        "\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/dl_biology-2.JPG)"
      ],
      "metadata": {
        "id": "iSwFhDc0Jwew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feedforward Neural Networks"
      ],
      "metadata": {
        "id": "wv_eNB60qnOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A feedforward neural network is a type of artificial neural network where information flows in one direction, from the input layer to the output layer, without any feedback loops.\n",
        "\n",
        "The simplest neural network architecture is a **single-layer perceptron**.\n",
        "- Single layer of input neurons\n",
        "- Connected by a weight to a single output neuron\n",
        "- The output of the perceptron is the weighted sum of the inputs passed through an activation function\n",
        "- The activation function introduces non-linearity into the model\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_perceptron-2.png)"
      ],
      "metadata": {
        "id": "ne3qnwnyNuhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "RrEg9mWyLUUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Process large and complex data through networks of synthetic neurons\n",
        "- Layers learn increasingly abstract representations of the data that  becomes input into predictions\n",
        "- Puts an emphasis on learning successive layers of increasingly meaningful representations\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/dl_deep_network-2.JPG)"
      ],
      "metadata": {
        "id": "-YYhu2BBLdVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inductive Inference"
      ],
      "metadata": {
        "id": "Jr8Xr97CMFOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Inductive inference is a type of reasoning that makes generalizations or predictions based on specific data or observations.\n",
        "- A hypothesis is inferred based on available data, but may not be true. But it's likely to be true within a certain level of confidence.\n",
        "- E.g. white swan examples"
      ],
      "metadata": {
        "id": "cwgBbzKuMNej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High-Level Abstractions"
      ],
      "metadata": {
        "id": "d_IXKfU9MaZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- High-level abstractions are simplified representations or models of complex systems or concepts.\n",
        "- They provide a way to understand complex ideas by breaking them down into simpler, more manageable parts that can be easily understood and manipulated."
      ],
      "metadata": {
        "id": "mjmBfsFDMfnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors"
      ],
      "metadata": {
        "id": "eOWaS5U3pJHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A tensor is like a multidimensional (multi-axis) array of numbers\n",
        "- Most DL frameworks use tensors as their basic data structure\n",
        "\n",
        "\n",
        "A tensor is defined by three key attributes:\n",
        "- Number of axes (rank): For instance, a 3D tensor has three axes, and a matrix has two axes.\n",
        "- Shape: This is an integer vector that describes how many dimensions the tensor has along each axis.\n",
        "- Data type: This is the type of the data contained in the tensor; for instance, a tensor’s type could be integer or double. On rare occasions, you may see a character tensor.\n",
        "\n",
        "Dimensionality:\n",
        "- Scalars (0D tensors): A tensor that contains only one number is called a scalar (or scalar tensor, or zero-dimensional tensor, or 0D tensor).\n",
        "- Vectors (1D tensors): A one-dimensional array of numbers is called a vector, or 1D tensor. A 1D tensor is said to have exactly one axis.\n",
        "- Matrices (2D tensors): A two-dimensional array of numbers is a matrix.\n",
        "- Arrays (3D and higher-dimensional tensors): If you pack such matrices in a new array, you obtain a 3D tensor. If you stack these arrays into another one, then you get a 4d tensor, and so forth…\n",
        "\n",
        "Examples:\n",
        "- 2D tensor - BW image - Height / Width - Each element is the intensity of a pixel with values ranging from 0 (black) to 255 (white).\n",
        "- 3D tensor - RGB image - Height / Width / Colour - Each element is the intensity of a pixel across three colours.\n",
        "- 3D tensor - BW video - Height / Width / Time - Each element is the intensity of a pixel and time.\n",
        "- 4D tensor - RGB video - Height / Width / Time / Colour - Think of each frame as a 3D tensor (height/widht/colour) stacked behind each other to form a 4D tensor (over time).\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/dl_tensors_funny-2.jpg)"
      ],
      "metadata": {
        "id": "9YaeQwd-Mxtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ],
      "metadata": {
        "id": "scL7FL8Tr4cD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A layer is a collection of neurons that process input data in a particular way.\n",
        "- Each layer performs some computation on input data, and produces output data, which is then passed on to the next layer.\n",
        "- Each layer typically has a specific purpose. E.g. detect edges or shapes in an image, or classify text into different categories.\n",
        "\n",
        "Types of layers:\n",
        "- Input Layer\n",
        "- Hidden Layer - purpose is to learn features of the input data, that is relevant to solving the networks task. Number of hidden layers / neurons per layer can be adjusted. Complex data = more hidden layers.\n",
        "- Output Layer\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ldurKtHcN3Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State / Stateless Layers"
      ],
      "metadata": {
        "id": "sSAZbhgaDMJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Layer with a state: The output of the layer depends not only on the current input, but also on the previous inputs and the current state of the layer. (E.g. in RNN's and sequential data)\n",
        "- Stateless layer: The output of the layer only depends on the input it receives at the current time, and not on any previous inputs that the layer has processed."
      ],
      "metadata": {
        "id": "zu9FdJicDopV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fully Connected Layer / Dense Layer"
      ],
      "metadata": {
        "id": "rhnuSYi8DGpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Each neuron in the layer is connected to each neuron in the previous layer with a weight."
      ],
      "metadata": {
        "id": "K1Eu2UmyFcwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation Functions"
      ],
      "metadata": {
        "id": "8ZZFj9T7rBBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- An activation function is a non-linear mathematical function applied to each neuron in a layer.\n",
        "- The non-linearity allows the network to learn and model more complex patterns in the data (otherwise it's just a simple linear combination of the inputs).\n",
        "\n",
        "\n",
        "Activations functions:\n",
        " - Sigmoid\n",
        "  - Maps the output of the neuron to a value between 0 and 1, which can be interpreted as a probability\n",
        " - ReLU (Rectified Linear Unit)\n",
        "  - Piecewise linear function that sets all negative inputs to zero and leaves positive inputs unchanged, which can help to speed up training and prevent the vanishing gradient problem\n",
        " - Tanh (hyperbolic tangent)\n",
        "  - Maps the output of the neuron to a value between -1 and 1, with a mean value of 0. Can make it easier to learn and optimize the weights and biases\n",
        " - Softmax\n",
        "  - Often used in the output layer of a classification network to produce a probability distribution over the possible classes."
      ],
      "metadata": {
        "id": "Ato1EbWAOHUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weights"
      ],
      "metadata": {
        "id": "5rqVSfSRq_vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Learnable parameter that determine the **strength** of the connections between neurons in different layers.\n",
        "- Weights are the parameters that determine how strongly the input of one neuron influences the output of another neuron in the next layer."
      ],
      "metadata": {
        "id": "zj1QikMiIJuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biases"
      ],
      "metadata": {
        "id": "JcBootJwIFkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bias is used to control the overall output of the neuron and to shift it in a particular direction\n",
        "- Biases are the parameters that determine how easily a neuron is activated or \"fired\".\n",
        "- Each neuron in a layer has a bias associated with it, which is added to the weighted sum of inputs before being passed through the activation function. "
      ],
      "metadata": {
        "id": "iMU61_ARIbqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Difference between weights and bias"
      ],
      "metadata": {
        "id": "w1j5H0lLxK5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Weights determine how much influence each input has on the neuron's output\n",
        "- Bias determines the overall output of the neuron.\n",
        "\n",
        "- Weights are used to adjust the strength of the connections between neurons\n",
        "- Bias is used to adjust the output of the neuron itself.\n",
        "\n",
        "Example: network trained to recognize handwritten digits\n",
        "- The weights in the network determine how much importance the network assigns to each pixel in the input image\n",
        "- The weights are learned during training to recognize the patterns that are common to the digits\n",
        "- The bias determines how likely the network is to output a particular digit, regardless of the input.\n",
        "- The bias is adjusted to ensure that the network outputs the correct digit with high probability."
      ],
      "metadata": {
        "id": "hpweO6WcxPTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Functions / Optimization Algorithms"
      ],
      "metadata": {
        "id": "SqnGUhv3sB-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mathematical function that measures the difference between the predicted output and the actual output.\n",
        "- The goal is to minimize this difference or \"loss\" by adjusting weights and biases\n",
        "- Choice of loss function depends on the type of problem\n",
        "\n",
        "\n",
        "- Iteratively adjusts the weights and biases based on the gradients of the loss function with respect to these parameters.\n",
        "\n",
        "Types of algorithms:\n",
        "- Gradient descent\n",
        " - Calculates the gradients of the loss function with respect to the model parameters, and adjusts the parameters in the direction that reduces the loss the most\n",
        "- Stochastic gradient descent\n",
        " - Variant of gradient descent that randomly samples a subset of the training data for each update, which can lead to faster convergence in some cases\n",
        "- Adam / Adagrad\n",
        " - Use adaptive learning rates to adjust the step size of the updates. Can result in faster convergence and better performance in some cases, especially for large-scale problems with many parameters.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_table_ann_config.png)"
      ],
      "metadata": {
        "id": "MFUpZfWeO06s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Score"
      ],
      "metadata": {
        "id": "j3-uJcvHswLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The numerical value of the loss function for a given set of input data and corresponding output predictions\n",
        "- During training, the loss score is calculated for each batch of input data and output predictions\n",
        "- Weights and biases of the network are then updated to minimize the value of the loss score using an optimization algorithm"
      ],
      "metadata": {
        "id": "Ckr9P0ZdKU8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output (Last Layer Activation)"
      ],
      "metadata": {
        "id": "1QfB8HL2r-y6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Produces the model's predictions or output values\n",
        "- Typically consists of one or more neurons, each of which corresponds to a specific output value or class label.\n",
        " - Binary classification problem: a single neuron produceing a probability score for the positive class\n",
        " - Multi-class classification problem: multiple neurons corresponding to different class labels\n",
        "\n",
        "Output layer activation functions depend on the problem:\n",
        "- Binary classification problem: sigmoid function to produce a probability score between 0 and 1\n",
        "- Multi-class classification problem: softmax function to produce a probability distribution across all possible classes"
      ],
      "metadata": {
        "id": "mz1ILAjsOmXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate"
      ],
      "metadata": {
        "id": "BSSbquLUybWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The learning rate determines the size of the steps taken towards the optimal weights and biases during this process in response to the error or loss gradient calculated during backpropagation.\n",
        "\n",
        "- High learning rate: weights and biases are adjusted more aggressively, resulting in faster convergence to the optimal values. However, it may overshoot the optimal values and fail to converge.\n",
        "\n",
        "- Low learning rate: weights and biases are adjusted more slowly, which may require more iterations to reach the optimal values. However, it's less likely to overshoot the optimal values and may result in a more accurate final model.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screen-Shot-2018-02-24-at-11.47.09-AM.png)"
      ],
      "metadata": {
        "id": "P9_dY32e_zeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size"
      ],
      "metadata": {
        "id": "zasunp_UydJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size determines the number of samples processed in each training iteration.\n",
        "\n",
        "The entire training dataset is typically too large to be processed at once. So it's divided into smaller batches of samples that can be processed in parallel.\n",
        "\n",
        "- Large batch size: more samples are processed in each iteration, which can result in faster training times on modern parallel processors. However, larger batch sizes also require more memory and may lead to overfitting if the model starts to memorize the training set.\n",
        "\n",
        "- Small batch size: fewer samples are processed in each iteration, which can result in slower training times but may also lead to better generalization performance by preventing overfitting.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/223642c7.jpg)"
      ],
      "metadata": {
        "id": "qWCLSeshA5QE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epochs"
      ],
      "metadata": {
        "id": "FJ7mrFdjyefk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of epochs determines how many times the neural network will train on the entire dataset. During an epoch, the neural network is trained on every sample in the training dataset at least once.\n",
        "\n",
        "- Many epochs: may lead to overfitting\n",
        "- Few epochs: may not reach an optimal solution\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/fa798161.jpg)"
      ],
      "metadata": {
        "id": "V5nxOBdoBp8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper parameters"
      ],
      "metadata": {
        "id": "3LGBaS3SQ1iU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Number of layers\n",
        "- Number of neurons per layer\n",
        "- Activation functions\n",
        "- Learning rate\n",
        "- Regularization parameters\n",
        "- Dropout rate\n",
        "- Batch szie\n",
        "- Number of epochs\n",
        "- Optimization algorithm\n",
        "- etc.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam/main/Group_Assignment_1/Illustrations/Neural%20Network%20Overview.jpg)"
      ],
      "metadata": {
        "id": "vGWBV7kIQ3Se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wandb.ai"
      ],
      "metadata": {
        "id": "s4KQzrEvzhvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wandb.ai is a performance visualization tool that can be used to track and visualize the performance of machine learning models in real-time. It allows you to easily visualize and analyze the results of your experiments, compare different models, and share your results with others.\n",
        "\n",
        "Wandb.ai can be used to track and visualize a variety of metrics such as accuracy, loss, and learning rate during the training process. It can also track other useful information such as model hyperparameters, dataset statistics, and hardware usage.\n",
        "\n"
      ],
      "metadata": {
        "id": "cT4oihpxzkHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Learning Problem"
      ],
      "metadata": {
        "id": "HySSgHV2PziJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a dataset of input-output pairs, the goal is to learn a function or model that can predict the correct output for any new input that it encounters.\n",
        "\n",
        "The learning problem can be categorized into two main types of tasks:\n",
        "- Supervised learning: the model is trained on a labeled dataset, where the inputs and corresponding outputs are provided. The model then learns to predict the output given a new input.\n",
        "- Unsupervised learning: the model is trained on an unlabeled dataset, where the inputs are provided without any corresponding outputs. The model then learns to discover patterns or structure in the data.\n",
        "- Other types: semi-supervised learning, reinforcement learning, transfer learning. "
      ],
      "metadata": {
        "id": "sSfk8vGdP1KK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Derivative of a Tensor operation: The Gradient"
      ],
      "metadata": {
        "id": "yq-s8Jx3QIB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A gradient is a vector that points in the direction of the greatest increase of a function\n",
        "- The gradient provides information about the direction and magnitude of the change needed to improve the model's performance\n",
        "- But you have to go in the direction of the negative gradient of the loss function.\n",
        "\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_gradient_1.jpg)"
      ],
      "metadata": {
        "id": "YfG4Sp-GQgQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "29HL2U2-sftC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Finding the global minimum\n",
        "- SGD is a variation of gradient descent. Instead of computing the gradient of the loss function on the entire training data, the gradient is computed on a small, randomly selected subset of the training set (mini-batch)\n",
        "- Model parameters (weights and biases) are updated based on the average gradient over the mini-batch.\n",
        "- If you update the weights in the opposite direction from the gradient, the loss will be a little less every time\n",
        "\n",
        "\n",
        "- Advantages:\n",
        " - Faster than regular gradient descent, especially on large datasets.\n",
        " - Introducing noise into the optimization process, which can help the model avoid getting stuck in local minima.\n",
        "- Disadvantages:\n",
        " - The random nature means updates to model parameters can be noisy and may not be in the best direction for minimizing the loss function.\n",
        " - This can lead to slower convergence and may require additional tuning of the learning rate or other hyperparameters.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_gradient_2.jpg)        ![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_gradient_3.jpg)"
      ],
      "metadata": {
        "id": "_11nxbD0Q08Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation Algorithm"
      ],
      "metadata": {
        "id": "ttdcde35smxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Backpropagation starts with the final loss value (in hte output layer) and works backward from the top layers to the bottom layers, applying the chain rule to compute the contribution that each parameter had in the loss value.\n",
        "- Typically used in conjunction with an optimization algorithm such as stochastic gradient descent (SGD) to iteratively update the weights and biases of the network until convergence."
      ],
      "metadata": {
        "id": "QUXGISD3RjoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview of Neural Network"
      ],
      "metadata": {
        "id": "8fgufSgkSD1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a neural network revolves around the following objects:\n",
        "- The layers which are combined into a network (or model)\n",
        "- The input data and corresponding outcome targets\n",
        "- The loss functio, which defines the feedback signal used for learning\n",
        "- The optimizer which determines how learning proceeds\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_deep_learning_parts-2.jpg)"
      ],
      "metadata": {
        "id": "b_pSr3f6SIIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classical Neural Network Architectures"
      ],
      "metadata": {
        "id": "sfRFfh3HqaZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network (ANN)"
      ],
      "metadata": {
        "id": "SXjZkI57oft7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NO MEMORY - Cannot be used on sequential data but can be used for cross-sectional prediction problems (e.g. identify cats and dogs**"
      ],
      "metadata": {
        "id": "kPquard5DKlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "DDS3tjlqolJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NO MEMORY - Cannot be used on sequential data but can be used for cross-sectional prediction problems (e.g. identify cats and dogs**\n",
        "\n",
        "A Convolutional Neural Network (CNN) is a type of deep learning algorithm designed to analyze and recognize visual patterns. It is inspired by the way our brain processes visual information.\n",
        "\n",
        "CNNs are made up of multiple layers of neurons that perform operations called convolutions. During convolution, the network processes the input image by applying a series of filters, which extract certain features from the image. These filters can detect patterns such as edges, corners, and curves.\n",
        "\n",
        "The output of one layer is fed as input to the next layer, and each layer learns to detect more complex features. The final layer of the network performs a classification task by identifying which object or feature is present in the input image.\n",
        "\n",
        "CNNs are commonly used in image and video recognition, object detection, and natural language processing tasks."
      ],
      "metadata": {
        "id": "T12hWpkhz--_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computer Vision"
      ],
      "metadata": {
        "id": "P8vDWc_Kt6LR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a CNN, the input image is represented as a 3D matrix where the first two dimensions represent the height and width of the image, and the third dimension represents the color channels. Here's an example of what a 3D matrix of an input image might look like:"
      ],
      "metadata": {
        "id": "q0z71yUp0zef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[\n",
        "  [[100, 120,  80], [ 90, 100,  70], [110, 105,  75]],\n",
        "  [[ 80,  90,  60], [ 75,  80,  55], [ 85,  75,  50]],\n",
        "  [[120, 125,  85], [110, 120,  80], [130, 115,  90]]\n",
        "]"
      ],
      "metadata": {
        "id": "gFMIY4ia092V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a 3x3x3 matrix, meaning it has 3 rows, 3 columns, and 3 color channels (red, green, and blue). Each element in the matrix represents the intensity value of a pixel at a specific location in the image.\n",
        "\n",
        "For example, in the first list [100, 120, 80], the first number 100 represents the intensity value of the red channel, the second number 120 represents the intensity value of the green channel, and the third number 80 represents the intensity value of the blue channel for the pixel located at the top-left corner of the input image."
      ],
      "metadata": {
        "id": "QGUkK5xC1AHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/maxresdefault.jpg)\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.20.29.png)"
      ],
      "metadata": {
        "id": "_5ec66iNwEw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Architecture"
      ],
      "metadata": {
        "id": "W1AXvSISuBX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.28.39.png)\n",
        "\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.29.39.png)"
      ],
      "metadata": {
        "id": "iR1SbGL4xTWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolution Layer & Convolution Filter"
      ],
      "metadata": {
        "id": "JL2XDvF6uFQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolution Layer**\n",
        "A convolution layer extracts features from an input image by applying a set of filters or kernels.\n",
        "\n",
        "During the convolution operation, each filter slides over the input image pixel by pixel, computing the dot product between the filter weights and the corresponding pixel values of the input image. This produces a single value in the output feature map. The filter then slides to the next pixel and the process is repeated until the filter has scanned the entire input image.\n",
        "\n",
        "By using multiple filters in a convolution layer, the CNN can detect a wide variety of features at different locations within the input image, such as edges, corners, and curves. These features can then be combined by subsequent layers of the network to recognize more complex patterns and objects within the image.\n",
        "\n",
        "Convolution layers are usually followed by other types of layers such as pooling layers or activation layers to further process the extracted features before passing them on to the next layer in the network.\n",
        "\n",
        "**Convolution Filter**\n",
        "A convolution filter, also known as a kernel, is a small matrix of numbers. The filter slides across the image, performing a mathematical operation at each position to create a new output feature map.\n",
        "\n",
        "Filters can be designed to detect different types of features and multiple filters are usually applied to the input image in a single convolution layer to extract different types of features. The resulting feature maps are then passed on to subsequent layers of the network for further processing and classification.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.32.57.png)\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.17.png)\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.06.png)"
      ],
      "metadata": {
        "id": "4i_lUgRiy0Bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downsampling (Pooling)"
      ],
      "metadata": {
        "id": "frnaEsJUuOVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downsampling is a technique to reduce the spatial dimensions of an image while retaining the important features and reduce computational complexity and prevent overfitting. This is also called pooling.\n",
        "\n",
        "During the pooling operation, a small window, usually 2x2 or 3x3, is slid over the feature map and a single value is selected from the window based on a specific rule, such as taking the maximum or average value, or global in the window. This reduces the size of the feature map by a factor of the window size.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.27.png)"
      ],
      "metadata": {
        "id": "Ydd9oP3LzHx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flattening"
      ],
      "metadata": {
        "id": "2OfK0L0Mw2T4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening refers to the process of converting a multi-dimensional tensor, such as a feature map, into a one-dimensional vector that can be fed into a fully connected layer for classification.\n",
        "\n",
        "After a series of convolution and pooling layers, the output feature map is a multi-dimensional tensor with height, width, and depth dimensions. Flattening this tensor involves rearranging the elements of the tensor into a single vector, which can then be fed into a fully connected layer for classification.\n",
        "\n",
        "For example, if the output feature map has dimensions of 7x7x64, flattening would result in a vector of length 3136 (7 x 7 x 64 = 3136)."
      ],
      "metadata": {
        "id": "0qB2C9gQ7780"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fully Connected Layers"
      ],
      "metadata": {
        "id": "domidFRLuSGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fully connected layer takes the output from the preceding convolution and pooling layers and performs a matrix multiplication with weights and biases to produce a classification output.\n",
        "\n",
        "A fully connected layer treats the input feature map as a one-dimensional vector and connects every neuron in the layer to every neuron in the previous layer. This means that every feature learned by the preceding layers can be used to make a prediction.\n",
        "\n",
        "The weights and biases in the fully connected layer are learned during the training process using backpropagation, which adjusts the values of the weights and biases to minimize the error between the predicted output and the true label."
      ],
      "metadata": {
        "id": "a5k_HNNL9xCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Region-Based Convolutional Neural Network (R-CNN)"
      ],
      "metadata": {
        "id": "qhOt9pf7uVnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used for object detection in images.\n",
        "\n",
        "R-CNN uses a combination of convolutional neural networks and region proposal algorithms to identify objects in an image.\n",
        "\n",
        "The R-CNN algorithm consists of three main components:\n",
        "\n",
        "Region proposal: a selective search algorithm that generates a set of candidate regions in an image that may contain objects.\n",
        "Feature extraction: a CNN is applied to each candidate region to extract a fixed-length feature vector.\n",
        "Classification: a set of support vector machines (SVMs) is trained to classify the feature vectors into the different object categories.\n",
        "The R-CNN approach enables the CNN to be applied to smaller, more localized regions of an image, reducing the computational burden of processing the entire image. \n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.40.png)\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-08%20at%2011.33.51.png)"
      ],
      "metadata": {
        "id": "91voleIqzONo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Optimization"
      ],
      "metadata": {
        "id": "Jm0XcQ_3uZ9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hyper-parameter tuning: learning rate, batch size, epochs, number of filters in each convolutional layer\n",
        "- Data augmentation: increase dataset size by rotating, flipping, scaling\n",
        "- Transfer learning: using a pre-trained models and fine-tune with your dataset\n",
        "- Regularization: dropout, L1/L2 regularization, and early stopping\n",
        "- Change architecture: find the optimal network architecture for a given problem (use academic articles)"
      ],
      "metadata": {
        "id": "N8yX_RVQyR97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Business Applications"
      ],
      "metadata": {
        "id": "87sx1D64ueHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Image recognition\n",
        " - product images and e-commerce websites\n",
        " - medical images in health care\n",
        "- Video analysis\n",
        " - detecting activity pattterns in surveillance footage\n",
        " - analysing consumer behavior in retail environments\n",
        "- Autonomous vehicles\n",
        " - self-driving cars\n",
        "- Object detection\n",
        " - quality control\n",
        " - security monitoring\n",
        "- Facial recognition"
      ],
      "metadata": {
        "id": "GyFcGLtBuoKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Network (RNN)"
      ],
      "metadata": {
        "id": "wwhjxlWGorYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HAS MEMORY - Can be used on sequential data**\n",
        "\n",
        "Sequential prediction problems:\n",
        "- To process a sequence or a temporal series of data points, you have to show the entire sequence to the network at once: turn it into a single data point.\n",
        "Therefore, often we would like to operate over sequences of vectors: Sequences in the input, the output, or in the most general case both.\n",
        "- Biological intelligence processes information incrementally while maintaining an internal model of what it’s processing, built from past information and constantly updated as new information comes in. Our thoughts have persistence.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_lstm_1.jpeg)"
      ],
      "metadata": {
        "id": "h-9XT1suDaC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Architecture"
      ],
      "metadata": {
        "id": "vuaXEv9bEt28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Each recurrent unit takes an input and the previous state as input, and computes a new state and an output. The new state is then used as the input to the next recurrent unit.\n",
        "\n",
        "- RNNs are networks with internal loops, allowing information to persist.\n",
        "- It processes sequences by iterating through the elements and maintaining a state containing information relative to what it has seen so far.\n",
        "- The state of the RNN is reset between processing two different, independent sequences, so you still consider one sequence a single data point: a single input to the network.\n",
        "- What changes is that this data point is no longer processed in a single step; rather, the network internally loops over sequence elements.\n",
        "\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_rnn_0.png)\n",
        "\n",
        "- Recurrent neural networks have the form of a chain of repeating modules of neural network.\n",
        "- In standard RNNs, this repeating module will have a very simple structure, such as a single tanh() layer.\n",
        "- It takes (differently) weighted input from the cells in the layer below, as well as of the state, which is just the “saved”/“remembered” layer below how it was one time-step earlier (at t-1).\n",
        "- Then, with the tanh(), it squisches all the weights together to an output bounded between [-1,1].\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_LSTM1.png)"
      ],
      "metadata": {
        "id": "QWTwEYMOGY9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loops"
      ],
      "metadata": {
        "id": "TcooySQGE7GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_t = 0 # the state as t\n",
        "\n",
        "for (input_t in input_sequence) {\n",
        "  output_t = f(input_t, state_t)\n",
        "  state_t = output_t                   \n",
        "}"
      ],
      "metadata": {
        "id": "PKP1ENkDHgCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To make these notions of loop and state clear, let’s implement the forward pass of a toy RNN .\n",
        "- This RNN takes as input a sequence of vectors, which you’ll encode as a 2D tensor of size (timesteps, input_features).\n",
        "- It loops over timesteps, and at each timestep, it considers its current state at t and the input at t (of shape (input_features), and combines them to obtain the output at t.\n",
        "- You’ll then set the state for the next step to be this previous output.\n",
        "For the first timestep, the previous output isn’t defined; hence, there is no current state. So, you’ll initialize the state as an all-zero vector called the initial state of the network."
      ],
      "metadata": {
        "id": "_OjnKh-iHlIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_t <- 0\n",
        "\n",
        "for (input_t in input_sequence) {\n",
        "  output_t <- activation(dot(W, input_t) + dot(U, state_t) + b)\n",
        "  state_t <- output_t\n",
        "}"
      ],
      "metadata": {
        "id": "ko7-8TwZHspT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can even flesh out the function f: the transformation of the input and state into an output will be parameterized by two matrices, W and U, and a bias vector b.\n",
        "- It’s similar to the transformation operated by a densely connected layer in a feedforward network."
      ],
      "metadata": {
        "id": "Q1Xl18cpHt6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations of RNN"
      ],
      "metadata": {
        "id": "LoMDOF-TFC3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Long-term Dependencies"
      ],
      "metadata": {
        "id": "e2DIM33rFHHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task.\n",
        "\n",
        "- Yet, going one step back is often not good enough, since meaning in some cases unfolds over a long sequence.\n",
        "\n",
        "- We just stack several layer_simple_rnnon top of each other to capture the information contained in long sequences? Kind of, but there is a probhlem…\n",
        "\n",
        "- In theory, RNNs are absolutely capable of handling such long-term dependencies.\n",
        "\n",
        "- Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by Hochreiter (1991, in German) and Bengio, et al. (1994)[^1], who found some pretty fundamental reasons why it might be difficult.\n",
        "\n",
        "- First and foremost, the valishing gradient problem."
      ],
      "metadata": {
        "id": "IUYCAt8iH3GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Backpropagation Through Time (BPTT)"
      ],
      "metadata": {
        "id": "ohF7OrTqFK1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Remember, the purpose of RNNs is to accurately classify sequential input.\n",
        "- We rely on the backpropagation of error and gradient descent to do so.\n",
        "- RNNs rely on an extension of backpropagation called backpropagation through time, or BPTT.\n",
        "- Time, in this case, is simply expressed by a well-defined, ordered series of calculations linking one time step to the next, which is all backpropagation needs to work.\n",
        "- Remember, neural networks, whether they are recurrent or not, are simply nested composite functions like y = f(g(h(x))).\n",
        "- Adding a time element only extends the series of functions for which we calculate derivatives with the chain rule."
      ],
      "metadata": {
        "id": "jX3ZXcbHH8gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Vanishing (Exploding) Gradient"
      ],
      "metadata": {
        "id": "5GGq8EwQCvZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The vanishing gradient problem occurs when gradients in a deep neural network become very small as they propagate backward from the output layer to the input layer during training.\n",
        "- This means that the weights in the earlier layers of the network are not updated significantly, and the network is unable to learn meaningful representations.\n",
        "- As a result, the network may perform poorly on complex tasks that require deep architectures.\n",
        "\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_vanishing_gradient.png)\n",
        "\n",
        "- Here you see the effects of applying a sigmoid function over and over again.\n",
        "- The data is flattened until, for large stretches, it has no detectable slope.\n",
        "- This is analogous to a gradient vanishing as it passes through many layers."
      ],
      "metadata": {
        "id": "ulUCNUt3ICG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary"
      ],
      "metadata": {
        "id": "UBrrdMUqIpgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In order to exploit the information of multiple recurrent layers, we have to find a way to train the weights while avoiding the vanishing gradient problem.\n",
        "- Therefore we introduce gates, through which previous states can pass through quasi unaltered."
      ],
      "metadata": {
        "id": "ctGClMsdIqlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Business Applications"
      ],
      "metadata": {
        "id": "I06YXKavW4fJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Text generation based on existing data\n",
        " - product descriptions\n",
        " - social media posts\n",
        "- Speech recognition\n",
        " - recognize and transcribe speech (e.g. call centers, voice based search)\n",
        "- Recommendation systems\n",
        " - predict user behaviour and make personalized recommendations\n",
        "- Fraud detection\n",
        " - Credit card fraud\n",
        " - Insurance fraud\n",
        "- Time series forecasting\n",
        " - sales traffic\n",
        " - website traffic"
      ],
      "metadata": {
        "id": "v8Lmefg_W6EI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Long Short-Term Neural Network (LSTM)"
      ],
      "metadata": {
        "id": "jO_4qjBUorWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HAS MEMORY - Can be used on sequential data**\n",
        "\n",
        "Sequential prediction problems:\n",
        "- To process a sequence or a temporal series of data points, you have to show the entire sequence to the network at once: turn it into a single data point.\n",
        "Therefore, often we would like to operate over sequences of vectors: Sequences in the input, the output, or in the most general case both.\n",
        "- Biological intelligence processes information incrementally while maintaining an internal model of what it’s processing, built from past information and constantly updated as new information comes in. Our thoughts have persistence.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_lstm_1.jpeg)"
      ],
      "metadata": {
        "id": "j4xyEHqfGRrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Architecture"
      ],
      "metadata": {
        "id": "apW82QZwFRLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LSTM's are a special kind of RNN, capable of learning long-term dependencies.\n",
        "- They introduced a variant of layer_simple_rnn; it adds a way to carry information across many timesteps.\n",
        "- Imagine a conveyor belt running parallel to the sequence you’re processing. Information from the sequence can jump onto the conveyor belt at any point, be transported to a later timestep, and jump off, intact, when you need it.\n",
        "- I.e., LSTM's save information for later, thus preventing older signals from gradually vanishing during processing.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_LSTM2.png)\n",
        "\n",
        "- LSTMs also have this chain like structure, but the repeating module has a different structure.\n",
        "- Instead of having a single neural network layer, there are four, interacting in a very special way.\n",
        "- In adittion to the layer with the tanh() activation function that produces [-1,1] outputs, we see adittional sigmoid() layers that produce output between [0,1]\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_LSTM_notation-2.png)\n",
        "\n",
        "In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others.\n",
        "\n",
        "- Pink circles represent pointwise operations, like vector addition\n",
        "- Yellow boxes are learned neural network layers.\n",
        "- Lines merging denote concatenation\n",
        "- Line forking denote its content being copied and the copies going to different locations.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_LSTM3.png)\n",
        "\n",
        "- The key to LSTMs is the cell state, the horizontal line running through the top of the diagram.\n",
        "- The cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions.\n",
        "- It’s very easy for information to just flow along it unchanged.\n",
        "- The LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.\n",
        "\n",
        "\n",
        "- Gates are a way to optionally let information through.\n",
        "- They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.\n",
        "- The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through.\n",
        "- A value of zero means “let nothing through,” while a value of one means “let everything through!”\n",
        "- An LSTM has three of these gates, to protect and control the cell state.\n",
        "-- The Forget Gate\n",
        "-- The Input gate\n",
        "-- The Output Gate\n",
        "- Conceptually, that is how an LSTM learns to remember as well as to forget. Lets inspect these layers more in detail.\n",
        "\n",
        "We can envision the architectur of an LSTM as follows:\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/DL_LSTM_architecture.png)"
      ],
      "metadata": {
        "id": "cfBJrtXCIf4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1: The Forget Gate Layer"
      ],
      "metadata": {
        "id": "5KA6TjWOFVCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The first step in our LSTM is to decide what information we’re going to throw away from the cell state.\n",
        "- This decision is made by a sigmoid layer called the **forget gate layer.*”** A 1 represents “completely keep this” while a 0 represents “completely get rid of this.”\n",
        "- Let’s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-16%20at%2016.59.04.png)"
      ],
      "metadata": {
        "id": "wZGfn9aPKlSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2: The Input Gate Layer"
      ],
      "metadata": {
        "id": "JPEVgBMBFXGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The next step is to decide what new information we’re going to store in the cell state. This has two parts.\n",
        "- First, a sigmoid layer called the input gate layer decides which values we’ll update.\n",
        "- Next, a tanh layer creates a vector of new candidate values, Ct, that could be added to the state.\n",
        "- In the next step, we’ll combine these two to create an update to the state.\n",
        "- In the example of our language model, we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-16%20at%2016.59.12.png)\n",
        "\n",
        "- It’s now time to update the old cell state, Ct−1, into the new cell state Ct.\n",
        "- The previous steps already decided what to do, we just need to actually do it. We multiply the old state by ft, forgetting the things we decided to forget earlier.\n",
        "- Then we add it∗Ct. This is the new candidate values, scaled by how much we decided to update each state value.\n",
        "- In the case of the language model, this is where we’d actually drop the information about the old subject’s gender and add the new information, as we decided in the previous steps.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-16%20at%2016.59.20.png)"
      ],
      "metadata": {
        "id": "aWkc11HVK1DF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3: The Output Gate Layer"
      ],
      "metadata": {
        "id": "tUFhUKbFFZ1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Finally, we need to decide what we’re going to output. This output will be based on our cell state, but will be a filtered version.\n",
        "- First, we run a sigmoid layer which decides what parts of the cell state we’re going to output.\n",
        "- Then, we put the cell state through tanh (to push the values to be between [−1,1]) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.\n",
        "- For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that’s what follows next.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-16%20at%2016.59.28.png)"
      ],
      "metadata": {
        "id": "_JOFx9XBLI-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary"
      ],
      "metadata": {
        "id": "qnGqaHEvImQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- In order to exploit the information of multiple recurrent layers, we have to find a way to train the weights while avoiding the vanishing gradient problem.\n",
        "- Therefore we introduce gates, through which previous states can pass through quasi unaltered.\n",
        "- However, not every information from previous sequences is useful for us. Indeed, too much information could be a curse rather than a blessing for our model.\n",
        "- Therefore, we have to introduce further gates that decide which information from previous stages to remember, and which to forget.\n",
        "\n",
        "The three main gates in an LSTM are:\n",
        "- Forget Gate: This gate decides what information to discard from the previous cell state.\n",
        "- Input Gate: This gate decides what new information to store in the cell state.\n",
        "- Output Gate: This gate decides what information to output from the current cell state."
      ],
      "metadata": {
        "id": "7Elni06bIgqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Business Applications"
      ],
      "metadata": {
        "id": "aO6oRt8KWNrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Future values of time series data\n",
        " - Stock prices\n",
        " - Energy consumption\n",
        " - website traffic\n",
        "- Anomaly detection\n",
        " - sudden spikes or drops in website traffic or sales\n",
        "- Sentiment analysis of\n",
        " - customer reviews\n",
        " - social media posts\n",
        "- Text classification\n",
        " - product descriptions\n",
        " - customer inquiries\n",
        "- Langauge translation\n",
        " - translate text from one language to another"
      ],
      "metadata": {
        "id": "7VCfgLuPWPu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Models"
      ],
      "metadata": {
        "id": "OJ5U3pxsorUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terms"
      ],
      "metadata": {
        "id": "iGqQbWyYMIrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Model"
      ],
      "metadata": {
        "id": "zIkE0HkQYrcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Introduced in 2017 (Attention is all you need)\n",
        "- Transformer models are a type of sequence-to-sequence model that are particularly well-suited for (NLP) tasks, such as language translation and text summarization.\n",
        "- Transformer models do not rely on sequential processing, and instead use a mechanism called self-attention to analyze the relationships between different elements in a sequence. This allows transformer models to capture long-range dependencies and handle variable-length sequences more efficiently than RNNs.\n",
        "- Transformer models are composed of two main parts:\n",
        " - The encoder takes an input sequence and produces a sequence of hidden states\n",
        " - The decoder takes the encoder's hidden states and produces an output sequence\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.03.36.png)"
      ],
      "metadata": {
        "id": "TU3npqnSYuNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention"
      ],
      "metadata": {
        "id": "SMgB4qrSMKSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Attention allows the model to give more weight to certain parts of the input while ignoring others.\n",
        "- Attention is considered better in transformer models than RNN and LSTM because it allows the model to focus on relevant parts of the input sequence while processing it, rather than processing the entire sequence at once.\n",
        "- Sttention mechanisms can be computed in parallel across the sequence (compared to sequential), making it more efficient for processing long sequences.\n",
        "- In NLP tasks, attention can be used to help the model understand the relationship between words in a sentence."
      ],
      "metadata": {
        "id": "ihNID4bXT319"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-Attention"
      ],
      "metadata": {
        "id": "kEDiWNEJdQn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Self-attention computes attention weights between different parts of a single sequence of input data.\n",
        "- Traditional attention is calculated between different sequences of data, such as when translating a sentence from one language to another. Self-attention, on the other hand, allows the model to attend to different parts of the same sequence.\n",
        "- Self-attention computes a set of attention weights for each element in the sequence, based on the similarity between that element and every other element in the sequence.\n",
        "- Self-attention allows the model to capture long-range dependencies and handle variable-length sequences more efficiently.\n",
        "\n",
        "\n",
        "The input sequence is transformed into three new sequences\n",
        " - The query sequence\n",
        " - The key sequence\n",
        " - The value sequence\n",
        "\n",
        "The attention weights between the query and key sequences are computed and used to obtain a weighted sum of the value sequence, which forms the output of the self-attention mechanism"
      ],
      "metadata": {
        "id": "Ph4GWphUZ0eI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Head Self-Attention"
      ],
      "metadata": {
        "id": "6Y_o6R3UdL1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Multi-head self-attention is a variation of self-attention \n",
        "- Allows the model to attend to different parts of the input sequence simultaneously. This makes transformer models more powerful and efficient than traditional attention-based models.\n",
        "\n",
        "In multi-head self-attention, the process of self-attention is repeated multiple times in parallel, with different sets of learnable query, key, and value transformations applied to the input sequence. The outputs of each of these parallel self-attention mechanisms are then concatenated and transformed again to obtain the final output of the multi-head self-attention layer.\n",
        "\n",
        "This can be thought of as learning different \"heads\" or \"perspectives\" of attention, each of which can capture different relationships between the input sequence elements. "
      ],
      "metadata": {
        "id": "IKzcO-dcYlJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Milestone Transformer Architectures"
      ],
      "metadata": {
        "id": "khiEMc8tMLyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BERT (Bidirectional Encoder Representations from Transformers): BERT is a transformer-based language model developed by Google in 2018. It uses a masked language modeling objective to train a bidirectional transformer encoder on a large corpus of text, and has achieved state-of-the-art results on a wide range of NLP tasks, such as question answering, sentiment analysis, and named entity recognition.\n",
        "- GPT (Generative Pre-trained Transformer): GPT is a series of transformer-based language models developed by OpenAI. The first iteration, GPT-1, was released in 2018 and used a standard transformer decoder to generate text. Later versions, such as GPT-2 and GPT-3, increased the model size and introduced new techniques such as multi-task learning and few-shot learning to improve performance.\n",
        "- T5 (Text-to-Text Transfer Transformer): T5 is a transformer-based model developed by Google in 2019 that can be trained on a variety of NLP tasks using a single, unified text-to-text format. It achieved state-of-the-art results on a variety of benchmarks, such as question answering and language translation.\n",
        "- Transformer-XL: Transformer-XL is a transformer-based model developed by Google in 2019 that incorporates a segment-level recurrence mechanism to handle longer sequences more efficiently. This model achieved state-of-the-art results on a variety of language modeling tasks."
      ],
      "metadata": {
        "id": "kAIGq6QqbQxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoder"
      ],
      "metadata": {
        "id": "gNRoWwcyMOZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- An autoencoder is trained to reconstruct its own input data.\n",
        "- It consists of two main parts:\n",
        " - an encoder that maps the input data to a lower-dimensional representation\n",
        " - a decoder that maps this representation back to the original input space.\n",
        "- The idea is to learn a compressed representation of the input data that captures its most important features, filtering out noise and irrelevant details.\n",
        "- Autoencoders have a wide range of applications, including:\n",
        " - Dimensionality reduction\n",
        " - Data compression\n",
        " - Anomaly detection\n",
        " - Data generation\n",
        " \n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2016.58.57.png)"
      ],
      "metadata": {
        "id": "35fyS9Z7TFmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq"
      ],
      "metadata": {
        "id": "Rud7WtY4McDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seq2seq (sequence-to-sequence) is a type of neural network that is used for mapping one sequence of values to another sequence of values.\n",
        "- The seq2seq model consists of two main parts: an encoder and a decoder. The encoder takes the input sequence and maps it to a fixed-length context vector. This context vector represents a compressed and abstracted representation of the input sequence. The decoder then takes the context vector as input and generates the output sequence one element at a time.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.00.15.png)\n",
        "\n",
        " ![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.02.07.png)"
      ],
      "metadata": {
        "id": "LWGG21jkTWzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder / Decoder"
      ],
      "metadata": {
        "id": "eqoCKw9eMruR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an Autoencoder:\n",
        "- An encoder is a neural network component that takes an input and maps it to a lower-dimensional representation, often referred to as the \"latent space\". The goal of the encoder is to capture the important features of the input and compress it into a more compact form.\n",
        "- A decoder is a neural network component that takes the encoded representation produced by the encoder and maps it back to the original input space. The decoder's goal is to reconstruct the original input from the encoded representation. \n",
        "\n",
        "In a Seq2Seq model:\n",
        "- The encoder takes an input sequence and produces a fixed-length context vector, which summarizes the information contained in the input sequence. \n",
        "-  The decoder then takes the context vector as input and generates the output sequence element by element.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.06.25.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.06.31.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.06.41.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.06.59.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.07.09.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.07.31.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.07.56.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.08.17.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.08.27.png)\n"
      ],
      "metadata": {
        "id": "n6E0VCFkaPFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semi-supervised vs. Supervised Training"
      ],
      "metadata": {
        "id": "2OQk-wjzbUh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.08.44.png)"
      ],
      "metadata": {
        "id": "HhTE74G3bW6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bi-Encoder"
      ],
      "metadata": {
        "id": "cJYiunt0MuA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Used for encoding text data into a fixed-length vector representation.\n",
        "- Consists of two separate encoding networks, one for the input text and one for the output text.\n",
        "- Encodes both the input and output texts independently, which can be useful in tasks such as question answering, information retrieval, and dialogue generation.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.09.09.png)"
      ],
      "metadata": {
        "id": "x80XPTCbbO5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Encoder"
      ],
      "metadata": {
        "id": "0nWgDHI8Mwx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Used for encoding pairs of text data into a fixed-length vector representation.\n",
        "- Takes both the input and output texts as a single sequence and encodes them together.\n",
        "- Often used in question answering, text classification, and natural language inference.\n",
        "- Typically more computationally expensive than bi-encoders due to the need to encode both inputs together.\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.09.17.png)"
      ],
      "metadata": {
        "id": "aYgoHVmmbRJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-Shot vs. Zero-Shot Learning"
      ],
      "metadata": {
        "id": "dcbZ1sTtcN4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Few-shot:\n",
        " - Learning from only a small number of examples or data points\n",
        " - Typically achieved by leveraging techniques such as transfer learning, meta-learning, or model-based reinforcement learning.\n",
        " - A few-shot learning model may be pre-trained on a large dataset of similar tasks and then fine-tuned on a smaller dataset of new tasks with only a few labeled examples.\n",
        "- Zero-shot:\n",
        " - ML paradigm in which a model is trained to recognize objects or tasks it has not seen during training.\n",
        " - Allows a model to generalize to new tasks or classes by leveraging information about the relationships between the existing classes.\n",
        " - Typically achieved by embedding objects or tasks into a common semantic space, such as a vector space, and learning a mapping from the input data to this space. The model can then recognize new objects or tasks by finding the closest semantic representation in the embedding space."
      ],
      "metadata": {
        "id": "vk5KN_1Nei3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence-Transformers (SBERT)"
      ],
      "metadata": {
        "id": "vr4wV4J7pcXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A sentence transformer is designed to encode and generate high-quality sentence embeddings, enabling accurate semantic similarity comparisons between sentences.\n",
        "- Sentence embeddings are dense vector representations of sentences that capture their semantic meaning\n",
        "- Ability to enable more intuitive, meaningful language-based search, content deduplication, and clustering.\n",
        "\n",
        "Diff. between BERT and SBERT\n",
        "- SBERT is optimized for generating high-quality sentence embeddings, while BERT was designed for a range of NLP tasks\n",
        "- SBERT outperforms BERT on semantic similarity tasks\n",
        "- SBERT typically more computationally efficient than BERT, making it more accessible for applications with limited resources\n",
        "- The choice between BERT and sentence transformers depends on the specific use case and the nature of the text data being analysed\n",
        "\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.42.48.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.42.59.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.43.11.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.43.25.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.44.37.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.45.07.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.45.31.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.45.40.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.45.56.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.46.08.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.46.20.png)\n",
        "![picture](https://raw.github.com/NadiaHolmlund/BDS_M4_Exam_Notes/main/Illustrations/Screenshot%202023-03-17%20at%2017.46.28.png)"
      ],
      "metadata": {
        "id": "lbAdCyHWVWbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Transformers (Hugging Face)\n"
      ],
      "metadata": {
        "id": "fqbXoYYEpcJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Wrapper for most common NLP transformer applications and architectures\n",
        "- Open-source Python library built on top of the Hugging Face Transformers library.\n",
        "- Provides high-level API for training and evaluating transformer-based models for a wide range of natural language processing (NLP) tasks, such as text classification, question answering, and named entity recognition. - Provides a simple and intuitive interface for fine-tuning pre-trained transformer models on custom datasets and supports a variety of training settings, such as early stopping, learning rate schedules, and mixed-precision training.\n",
        "\n",
        "Hugging Face: Pre-trained models, datasets, spaces and their libraries (pytorch), transformers, setfit (few-shot tuning)"
      ],
      "metadata": {
        "id": "9AM3NDqpVmug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applications"
      ],
      "metadata": {
        "id": "irc2t0tBg_y0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Multi-modal\n",
        " - text-to-image\n",
        " - image-to-text\n",
        " - visual question answering\n",
        " - feature extraction\n",
        "- Computer vision\n",
        " - image classification\n",
        " - object detection\n",
        " - image-to-image\n",
        " - video classification\n",
        "- NLP\n",
        " - text classification\n",
        " - token classification\n",
        " - question answering\n",
        " - translation\n",
        " - summarization\n",
        " - fill-mask\n",
        " - text generation\n",
        " - sentence similarity\n",
        "- Audio\n",
        " - text-to-speech\n",
        " - automatic speech recognition\n",
        " - audio-to-audio\n",
        " - audio classification\n",
        "- Tabular\n",
        "- Reinforcement learning"
      ],
      "metadata": {
        "id": "7RPZ7CauhBqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group Assignments"
      ],
      "metadata": {
        "id": "4OKEkH-FtB3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Assignment 1\n",
        "This folder contains an Airbnb price prediction model created with Pytorch and demonstrated in Gradio.\n",
        "\n",
        "The notebook goes through the following process:\n",
        "\n",
        "1. Data preprocessing\n",
        "2. Feature engineering\n",
        "3. Definition and training of a neural network model with Pytorch\n",
        "4. Experimentation with hyperparameters\n",
        "5. Model evaluation\n",
        "6. Model demonstration in Gradio\n",
        "\n",
        "An example model is imported as default for experimentation with hyperparameters, based on which 6 experiments are conducted. The experiments touch upon the following types of hyperparameters:\n",
        "\n",
        "Experiment 1: Activation Function\n",
        "\n",
        "Experiment 2: Loss Function\n",
        "\n",
        "Experiment 3: Hidden Layers\n",
        "\n",
        "Experiment 4: Epochs\n",
        "\n",
        "Experiment 5: Learning Rate\n",
        "\n",
        "Experiment 6: Loss Function\n",
        "\n",
        "\n",
        "The models are then evaluated on the test data by means of R^2 and MSE and the best performing model is demonstrated in Gradio.\n",
        "\n",
        "If wanted, the other models can be implemented and demonstrated in Gradio as well."
      ],
      "metadata": {
        "id": "RtLu-5HpfdGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Assignment 2\n",
        "This folder contains a CNN image classification model and a LSTM temperature prediction model created with pytorch.\n",
        "\n",
        "The notebooks go through the following process:\n",
        "1. Data preprocessing\n",
        "2. Feature engineering\n",
        "3. Definition and training of a neural network model with Pytorch\n",
        "4. Experimentation with hyperparameters\n",
        "5. Model evaluation"
      ],
      "metadata": {
        "id": "qoiII7APfg-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Assignment 3\n",
        "This folder contains a Netflix recommendation model created with SBERT and demonstrated in Gradio.\n",
        "\n",
        "Based on a user-defined text-input, the model recommends a Netflix movie/TV-series which matches the search-prompt as much as possible.\n",
        "\n",
        "The notebook goes through the following process:\n",
        "1. Data preproccesing and feature engineering\n",
        "2. Modelling using SBERT and cosine similarity\n",
        "3. Demonstrating the model in Gradio"
      ],
      "metadata": {
        "id": "YYNNp6nefjMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Assignment 4\n",
        "This folder contains a fine tuned Japanese speech recognition model and have been fine tuned with the Common Voice dataset.\n",
        "\n",
        "\n",
        "The notebook contains the following:\n",
        "1. Preprocessing the data\n",
        "2. Training\n",
        "3. Pushing the model to Hugging Face Hub\n",
        "4. Gradio\n",
        "5. Gradio with Google API\n",
        "\n",
        "Links:\n",
        "- [Japanese Fine Tuned Whisper Model](https://huggingface.co/Nikolajvestergaard/Japanese_Fine_Tuned_Whisper_Model)\n",
        "- [Real-time demo for Japanese speech recognition](https://huggingface.co/spaces/NadiaHolmlund/Japanese_Fine_Tuned_Whisper_Model)\n",
        "- [Japanese to English translator](https://huggingface.co/spaces/NadiaHolmlund/Japanese_Fine_Tuned_Whisper_Model_2)\n",
        "- [Convert Japanese speech to text, get pronunciation and translation to English](https://huggingface.co/spaces/NadiaHolmlund/Japanese_Fine_Tuned_Whisper_Model_3)"
      ],
      "metadata": {
        "id": "R8Yb0OsoflS1"
      }
    }
  ]
}